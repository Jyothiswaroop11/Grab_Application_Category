# ğŸ¯ Grab_Application_Category

## ğŸ“‹ Description
A web scraping tool to automatically extract category and subcategory information from Palo Alto Networks Applipedia for given applications.

## ğŸš€ Features
- Automated web scraping from Applipedia
- Batch processing of multiple applications
- Excel input/output support
- Headless browser operation
- Auto-formatted Excel output with proper alignment and text wrapping

## ğŸ› ï¸ Prerequisites
```bash
python >= 3.7
pip
Chrome browser
```

## ğŸ“¦ Dependencies
```bash
selenium
pandas
openpyxl
webdriver_manager
```

## âš™ï¸ Installation
1. Clone the repository:
```bash
git clone https://github.com/yourusername/Grab_Application_Category.git
cd Grab_Application_Category
```

2. Install requirements:
```bash
pip install -r requirements.txt
```

## ğŸ“ Project Structure
```
Grab_Application_Category/
â”œâ”€â”€ Excel_Files/
â”‚   â”œâ”€â”€ inputfile.xlsx
â”‚   â””â”€â”€ output.xlsx
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

## ğŸ“ Input Format
Create `Excel_Files/inputfile.xlsx` with applications in first column:
```
Application
adobe
abs
cisco
```

## ğŸ® Usage
1. Prepare input Excel file:
   - Place URLs in first column
   - Save as `Excel_Files/inputfile.xlsx`

2. Run script:
```bash
python main.py
```

3. Find results in `Excel_Files/output.xlsx`

## ğŸ“Š Output Format
The script generates an Excel file with:
- SNO: Serial number
- URL: Application name
- Category: Application categories
- Sub Category: Application subcategories

## âš ï¸ Error Handling
- Invalid URLs: Marked as "Not Found"
- Network issues: Error messages in console
- Missing input file: Directory creation prompt

## ğŸ”§ Customization
Adjust these constants in `main.py`:
```python
CHROME_WAIT_TIME = 20  # Selenium wait time
BASE_URL = "https://applipedia.paloaltonetworks.com/"
```

## ğŸ™ Acknowledgments
- Palo Alto Networks for Applipedia
- Selenium WebDriver team
- ChromeDriver developers
